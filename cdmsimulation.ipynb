{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tools import bootstrap_ci\n",
    "from joblib import Parallel, delayed\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm,trange\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename= \"sim_results.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prol_data = pd.read_csv(\"responses.csv\")\n",
    "prol_data[\"advice\"]=prol_data[\"advice\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_styles = (\n",
    "    (\"exp4\", \"C2\", \"EXP4\", '^'),\n",
    "    (\"random_expert\", \"C4\", \"random expert\", 'D'),\n",
    "    (\"WMV\", \"C1\", \"WMV\", 'v'),\n",
    "    (\"expert_0\", \"C7\", \"best expert\", '>'),\n",
    "    (\"MetaCMAB\", \"C0\", \"MetaCMAB\", '<'),\n",
    "    (\"ExpertiseTree\", \"black\", \"ExpertiseTree\", 'p'),\n",
    ")\n",
    "\n",
    "\n",
    "def get_all_results(k, subset_size, treatment=None):\n",
    "\n",
    "    if k == \"random_expert\":\n",
    "        results = []\n",
    "        for i in range(subset_size):\n",
    "            results.append(get_all_results(f\"expert_{i}\",subset_size,treatment))\n",
    "        return np.mean(results,axis=0)\n",
    "    with h5py.File(hdf5_filename, 'r') as hf:\n",
    "        if f\"{subset_size} {0} {k}\" not in hf:\n",
    "            return None\n",
    "        results = []\n",
    "        for tr in range(5):\n",
    "            data = hf[f\"{subset_size} {tr} {k}\"]\n",
    "            if tr == treatment:\n",
    "                return np.array(data)\n",
    "\n",
    "            results.extend(np.array(data).reshape((-1, 16)))\n",
    "\n",
    "        return np.array(results)\n",
    "\n",
    "\n",
    "def print_summary(SUBSET_SIZE):\n",
    "    print(\"algorithm\"+\" \"*max(1, 35-len(\"algorithm\")), \"  mean\", \"  final\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    with h5py.File(hdf5_filename, 'r') as hf:\n",
    "\n",
    "        algorithms = set([\" \".join(key.split()[2:])\n",
    "                         for key in hf.keys() if key.split()[0] == str(SUBSET_SIZE)])\n",
    "\n",
    "        for k in sorted(algorithms):\n",
    "            try:\n",
    "                all_results = get_all_results(k, SUBSET_SIZE)\n",
    "                reward_mean = np.mean(all_results)\n",
    "                final_reward_mean = np.mean(all_results[..., -1:])\n",
    "\n",
    "                print(k+\" \"*max(1, 35-len(k)), f\"{reward_mean:.4f}\", f\"{final_reward_mean:.4f}\")\n",
    "            except:\n",
    "                print(\"skipping\", k)\n",
    "\n",
    "\n",
    "def plot_subset_figures(SUBSET_SIZE):\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "    def transform(a):\n",
    "        ref_key = \"expert_0\"\n",
    "        if mode == \"instantaneous regret\":\n",
    "            return np.array(get_all_results(ref_key, SUBSET_SIZE))-a\n",
    "        if mode == \"regret\":\n",
    "            a = np.array(get_all_results(ref_key, SUBSET_SIZE))-a\n",
    "            return np.cumsum(a, axis=1)\n",
    "        if mode == \"average\":\n",
    "            return np.cumsum(a,axis=1)/np.arange(1,len(a[0])+1)\n",
    "      \n",
    "        return a\n",
    "\n",
    "    def plot_k_c(alg_key, alg_color, alg_label, alg_marker):\n",
    "        metric = transform(np.array(get_all_results(alg_key, SUBSET_SIZE)))\n",
    "        mean = metric.mean(axis=0)\n",
    "\n",
    "        lower_bound, upper_bound = np.array(\n",
    "            [bootstrap_ci(metric[:, i],n_bootstraps=1000) for i in range(T)]).T\n",
    "\n",
    "        plt.plot(np.arange(len(mean))*3, (mean), color=alg_color, label=alg_label,\n",
    "                 linestyle=\"--\" if alg_label not in (\"MetaCMAB\", \"ExpertiseTree\") else \"-\", marker=alg_marker,\n",
    "                 linewidth=4, markersize=8 if alg_marker == 'D' else 10)\n",
    "        plt.fill_between(x=np.arange(len(mean))*3, y1=lower_bound,\n",
    "                         y2=upper_bound, color=alg_color, alpha=0.2)\n",
    "\n",
    "    for mode in ( \"instantaneous regret\",):\n",
    "\n",
    "        for alg_key, alg_color, alg_label, alg_marker in alg_styles:\n",
    "            if get_all_results(alg_key, SUBSET_SIZE) is None:\n",
    "                continue\n",
    "\n",
    "            plot_k_c(alg_key, alg_color, alg_label, alg_marker)\n",
    "\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        plt.ylabel(mode.replace(\"reward\", \"accuracy\"))\n",
    "        plt.xlabel(\"#headlines\")\n",
    "\n",
    "        if mode in (\"reward\", \"average\"):\n",
    "            plt.yticks([0.5, 0.6, .7, .8, .9])\n",
    "\n",
    "        if mode == \"instantaneous regret\":\n",
    "            plt.ylim(-0.12, 0.3)\n",
    "            plt.yticks([-0.1, 0, .1, .2, .3])\n",
    "\n",
    "        plt.gca().set_box_aspect(1)\n",
    "        sns.despine(offset=0,)\n",
    "\n",
    "        plt.savefig(f\"figures/{mode}_{SUBSET_SIZE}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.savefig(f\"figures/{mode}_{SUBSET_SIZE}.svg\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import *\n",
    "from policy import *\n",
    "\n",
    "\n",
    "class GreedyExpert():\n",
    "    def __init__(self, expert_index, performance_index):\n",
    "        self.expert_index = expert_index\n",
    "        self.performance_index = performance_index\n",
    "\n",
    "    def choose(self, advice):\n",
    "        play_advice = advice[\"advice\"][self.expert_index]\n",
    "        probs = greedy_choice(play_advice)\n",
    "        return np.searchsorted(np.cumsum(probs), np.random.rand(1))[0]\n",
    "\n",
    "    def update(self, rewards, action):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def run_simulation(\n",
    "    advice,\n",
    "    outcomes,\n",
    "    contexts,\n",
    "    agent,\n",
    "    seed,\n",
    "    subset_size,\n",
    "    n_simulations=100\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    run_seeds = np.random.randint(0, 1000000, size=n_simulations)\n",
    "    n_trials, n_arms, n_experts = advice.shape\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    assert 0 < subset_size <= n_experts\n",
    "\n",
    "    simulation_subsets = [np.random.choice(\n",
    "        n_experts, size=subset_size, replace=False) for _ in range(n_simulations)]\n",
    "\n",
    "    rewards = []\n",
    "\n",
    "    for run_seed, subset in tqdm(zip(run_seeds, simulation_subsets), total=n_simulations, desc=\"inner\", disable=True):\n",
    "\n",
    "        np.random.seed(run_seed)\n",
    "        rewards.append([])\n",
    "\n",
    "        t_order = np.random.choice(n_trials, size=n_trials, replace=False)\n",
    "\n",
    "        sim_advice = advice[t_order][..., subset]\n",
    "        sim_outcomes = outcomes[t_order][..., subset]\n",
    "        sim_contexts = contexts[t_order]\n",
    "\n",
    "        # assign appropriate expert\n",
    "        if type(agent) == GreedyExpert:\n",
    "            expert_votes = greedy_choice(sim_advice, axis=1)\n",
    "            expert_rewards = (expert_votes * sim_outcomes).sum(axis=1)\n",
    "            agent.expert_index = np.argsort(-expert_rewards.sum(axis=0))[\n",
    "                agent.performance_index]\n",
    "\n",
    "        agent.reset()\n",
    "        for t in range(n_trials):\n",
    "            np.random.seed(run_seed + t)\n",
    "\n",
    "            trial_rewards = sim_outcomes[t][..., 0]\n",
    "\n",
    "            choice = agent.choose(\n",
    "                {\"advice\": sim_advice[t].T, \"context\": sim_contexts[t]})\n",
    "            agent.update(trial_rewards, choice)\n",
    "\n",
    "            rewards[-1].append(trial_rewards[choice])\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sizes = np.arange(2,37,2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_treatment = [prol_data.query(\"treatment == @treatment\").sort_values(\n",
    "    by=[\"trial\", \"arm\", \"expert_id\"]) for treatment in range(5)]\n",
    "\n",
    "SEED = 1234\n",
    "n_simulations = 1000\n",
    "simulations_per_process = 25\n",
    "np.random.seed(SEED)\n",
    "simulation_seeds = np.random.randint(2**16-1,size=np.ceil(n_simulations / simulations_per_process).astype(int))\n",
    "\n",
    "for sim_n_experts in tqdm(subset_sizes,desc=\"subset sizes\"):\n",
    "    for treatment in trange(5, desc=\"treatment\", disable=False):\n",
    "\n",
    "        treatment_data = data_by_treatment[treatment].copy()\n",
    "        N_ARMS = treatment_data.arm.nunique()\n",
    "        N_EXPERTS = treatment_data.expert_id.nunique()\n",
    "        T = treatment_data.trial.nunique()\n",
    "\n",
    "        advice, outcomes = treatment_data[[\n",
    "            \"advice\", \"genuine\",\n",
    "        ]].values.T.reshape((-1, T, N_ARMS, N_EXPERTS))\n",
    "\n",
    "        contexts = np.rollaxis(treatment_data[[\n",
    "            \"outcome:white\", \"outcome:male\", \"outcome:young\"\n",
    "        ]].abs().values.T.reshape((-1, T, N_ARMS, N_EXPERTS))[..., 0], 0, 3)\n",
    "\n",
    "        aggregators = {\n",
    "            \"WMV\": Collective(N_ARMS, GreedyPolicy(), sim_n_experts),\n",
    "            \"exp4\": Exp4(N_ARMS, Exp3Policy(), sim_n_experts, gamma=np.sqrt(0.5 * np.log(sim_n_experts + 1) / (N_ARMS * T))),\n",
    "            \"MetaCMAB\":  MetaCMAB(N_ARMS, GreedyPolicy(), sim_n_experts ),\n",
    "            \"ExpertiseTree\": ExpertiseTree(N_ARMS, GreedyPolicy(), sim_n_experts),\n",
    "        }\n",
    "        for i in range(sim_n_experts):\n",
    "            aggregators[f'expert_{i}'] = GreedyExpert(None, i)\n",
    "\n",
    "        bar = tqdm(aggregators.items(), total=len(\n",
    "            aggregators), disable=False, desc=\"aggregators\")\n",
    "        for k, agent in bar:\n",
    "            dataset_key = f\"{sim_n_experts} {treatment} {k}\"\n",
    "            bar.set_description(k)\n",
    "            \n",
    "            if  os.path.exists(hdf5_filename):\n",
    "                with h5py.File(hdf5_filename, 'r') as hf:\n",
    "                    if dataset_key in hf:\n",
    "                        continue\n",
    "\n",
    "            results = Parallel(n_jobs=8)(delayed(run_simulation)(\n",
    "                advice, outcomes, contexts, agent, seed, sim_n_experts, \n",
    "                simulations_per_process if (i + 1) * simulations_per_process <= n_simulations else n_simulations - i * simulations_per_process) for i,seed in enumerate(simulation_seeds))\n",
    "            results = np.array(results).reshape((-1, T))\n",
    "\n",
    "            with h5py.File(hdf5_filename, 'a') as hf:\n",
    "                if dataset_key in hf:\n",
    "                    del hf[dataset_key]\n",
    "                hf.create_dataset(dataset_key, data=results)\n",
    "\n",
    "    print_summary(sim_n_experts)\n",
    "    plot_subset_figures(sim_n_experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axes = plt.subplots(2,5)\n",
    "fig.set_size_inches(18.5, 6)\n",
    "row_length=5\n",
    "for n,subset_size in enumerate([2]+np.arange(4,37,4).tolist()):\n",
    "    row_labels = ('ExpertiseTree','MetaCMAB',\"WMV\",\"exp4\",\"random_expert\")[::-1]\n",
    "    proper_labels = ['ExpertiseTree',\"MetaCMAB\",\"WMV\",\"EXP4\",\"random member\"][::-1]\n",
    "    \n",
    "\n",
    "    reference_results =  np.array([get_all_results(f'expert_{i}',subset_size)[...,:].mean(axis=-1) for i in range(subset_size)])\n",
    "    alg_results = [get_all_results(k,subset_size)[...,:].mean(axis=-1) for k in row_labels]\n",
    "\n",
    "    percent_scores=np.array([(((alg_results[j]>=reference_results)).mean(axis=1) + ((alg_results[j]>reference_results)).mean(axis=1))/2 for j in range(len(row_labels))])\n",
    "    print(subset_size,percent_scores[-2:,...,:2])\n",
    "    j=n%row_length\n",
    "    i=n//row_length\n",
    "    im = axes[i,j].imshow(percent_scores,aspect=.12,extent=[0,1,0,len(row_labels)],cmap=\"seismic\",vmin=0,vmax=1)\n",
    "\n",
    "    if j==0:\n",
    "        axes[i,j].set_yticks(np.arange(len(row_labels))+.5, proper_labels[::-1])\n",
    "        axes[i,j].set_ylabel(\"algorithm\")\n",
    "    else:\n",
    "        axes[i,j].set_yticks(np.arange(len(row_labels))+.5, [\"\"]*len(row_labels))\n",
    "    if i==0:\n",
    "        \n",
    "        axes[i,j].set_xticklabels([])\n",
    "    else:\n",
    "        axes[i,j].set_xticklabels(['0','0.5','1'])\n",
    "\n",
    "    if i==1:\n",
    "        axes[i,j].set_xlabel(\"member quantile\")\n",
    "    axes[i,j].set_title(f\"N={subset_size}\")\n",
    "    \n",
    "cbar_ax = fig.add_axes([0.925, 0.125, 0.01, 0.7])\n",
    "cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "cbar.ax.get_yaxis().labelpad = 25\n",
    "cbar.set_label('win ratio', rotation=270)\n",
    "plt.savefig(f\"figures/quantile_heatmap.pdf\",bbox_inches=\"tight\")\n",
    "plt.savefig(f\"figures/quantile_heatmap.svg\",bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for alg_key, alg_color, alg_label, alg_marker in alg_styles:\n",
    "    try:\n",
    "        results = [get_all_results(alg_key,subset_size).mean(axis=-1) for subset_size in subset_sizes]\n",
    "    except:\n",
    "        continue\n",
    "    means = [np.mean(result) for result in results]\n",
    "    print(alg_key,np.mean(means))\n",
    "    cis = np.array([bootstrap_ci(result) for result in results])\n",
    "    \n",
    "    plt.plot(subset_sizes,means,  color=alg_color, label=alg_label, \n",
    "             linestyle=\":\" if 'b' in alg_key else \"--\" if alg_label not in (\"MetaCMAB\", \"ExpertiseTree\") else \"-\", \n",
    "             linewidth=4, markersize=8 if alg_marker == 'D' else 10,\n",
    "             marker=alg_marker)\n",
    "\n",
    "    plt.fill_between(subset_sizes, cis[:,0],cis[:,1], color=alg_color, alpha=.2)\n",
    "\n",
    "\n",
    "plt.xlabel(\"group size\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "sns.despine()\n",
    "plt.gca().set_box_aspect(1)\n",
    "sns.despine(offset=0,)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"figures/average_reward.pdf\",bbox_inches=\"tight\") \n",
    "plt.savefig(\"figures/average_reward.svg\",bbox_inches=\"tight\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for alg_key, alg_color, alg_label, alg_marker in alg_styles:\n",
    "    \n",
    "    try:\n",
    "        results = [get_all_results(\"expert_0\",subset_size)[:,-1]-get_all_results(alg_key,subset_size)[:,-1] for subset_size in subset_sizes]\n",
    "    except:\n",
    "        continue\n",
    "    means = [np.mean(result) for result in results]\n",
    "    print(alg_key,np.mean(means))\n",
    "    cis = np.array([bootstrap_ci(result) for result in results])\n",
    "    plt.plot(subset_sizes,means, color=alg_color, label=alg_label, \n",
    "             linestyle=\":\" if 'b' in alg_key else \"--\" if alg_label not in (\"MetaCMAB\", \"ExpertiseTree\") else \"-\", \n",
    "             linewidth=4, markersize=8 if alg_marker == 'D' else 10,\n",
    "             marker=alg_marker)\n",
    "\n",
    "    plt.fill_between(subset_sizes, cis[:,0],cis[:,1], color=alg_color, alpha=.2)\n",
    "\n",
    "\n",
    "plt.xlabel(\"group size\")\n",
    "plt.ylabel(\"terminal regret\")\n",
    "plt.gca().set_box_aspect(1)\n",
    "sns.despine(offset=0,)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"figures/final_reward.pdf\",bbox_inches=\"tight\") \n",
    "plt.savefig(\"figures/final_reward.svg\",bbox_inches=\"tight\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
